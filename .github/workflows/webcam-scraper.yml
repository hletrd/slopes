name: Webcam URL Scraper

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.PAT }}
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4

      - name: Create scripts directory if it doesn't exist
        run: mkdir -p scripts

      - name: Create webcam scraper script
        run: |
          cat > scripts/webcam_scraper.py << 'EOF'
          import requests
          from bs4 import BeautifulSoup
          import json
          import re
          import time
          import os

          def extract_m3u8_from_url(url):
              headers = {
                  'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36'
              }

              try:
                  response = requests.get(url, headers=headers)
                  response.raise_for_status()

                  soup = BeautifulSoup(response.text, 'html.parser')

                  page_text = soup.get_text()
                  m3u8_matches = re.findall(r'https?://[^\s\'"]+\.m3u8[^\s\'"]*', page_text)
                  if m3u8_matches:
                      return m3u8_matches[0]

                  for script in soup.find_all('script'):
                      if script.string:
                          script_m3u8 = re.findall(r'https?://[^\s\'"]+\.m3u8[^\s\'"]*', script.string)
                          if script_m3u8:
                              return script_m3u8[0]

                  for tag in soup.find_all(True):
                      for attr in tag.attrs:
                          if isinstance(tag[attr], str) and '.m3u8' in tag[attr]:
                              attr_m3u8 = re.findall(r'https?://[^\s\'"]+\.m3u8[^\s\'"]*', tag[attr])
                              if attr_m3u8:
                                  return attr_m3u8[0]

                  return None
              except Exception as e:
                  print(f"Error extracting m3u8 from {url}: {e}")
                  return None

          try:
              print("Reading links.json file...")
              with open('links.json', 'r', encoding='utf-8') as f:
                  data = json.load(f)

              modified = False

              for resort in data:
                  resort_id = resort.get('id', 'unknown')
                  print(f"Processing resort: {resort_id}")

                  if 'links' in resort:
                      links = resort.get('links', [])
                      for item in links:
                          link = item.get('link')
                          video = item.get('video')

                          if link and (not video or not video.endswith('.m3u8')):
                              print(f"Processing link: {link}")

                              if link.endswith('.m3u8'):
                                  item['video'] = link
                                  print(f"Link is already an m3u8 link: {link}")
                                  modified = True
                              else:
                                  m3u8_link = extract_m3u8_from_url(link)
                                  if m3u8_link:
                                      item['video'] = m3u8_link
                                      print(f"Found m3u8 link: {m3u8_link}")
                                      modified = True
                                  else:
                                      print(f"No m3u8 link found for {link}")
                          else:
                              if video:
                                  print(f"Already has video link: {video}")
                              else:
                                  print(f"No link available")

              if modified:
                  print("Saving updated links.json file...")
                  with open('links.json', 'w', encoding='utf-8') as f:
                      json.dump(data, f, ensure_ascii=False, indent=2)
                  print("Saved links.json successfully")
              else:
                  print("No changes to links.json")

          except Exception as e:
              print(f"Error processing links.json: {e}")
          EOF

      - name: Run scraper
        run: python scripts/webcam_scraper.py

      - name: Configure Git
        run: |
          git config --local user.email "01@0101010101.com"
          git config --local user.name "Jiyong Youn"

      - name: Commit changes
        run: |
          git add links.json
          git diff --quiet && git diff --staged --quiet || git commit -m "[Bot] Update webcam links"

      - name: Push changes
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.PAT }}
          branch: ${{ github.ref }}